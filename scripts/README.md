# Fairness in Human-Centered Knowledge Access

This repository contains code and experiments for the paper:

**"Fairness in Human-Centered Knowledge Access: A Theoretical Framework for Guaranteed Equitable AI Systems"**

We propose a fairness-aware recommendation framework with provable guarantees, designed for educational and digital library environments.

---

## ğŸš€ Features
- Synthetic dataset generation with group-biased relevance
- Fairness Enforcement Algorithm (FEA) for group exposure parity and envy-freeness
- Utility, disparity, and envy evaluation metrics

---

## ğŸ›  Installation
```bash
pip install -r requirements.txt
```

---

## ğŸ“¦ Project Structure
```
fairness-knowledge-access/
â”œâ”€â”€ data/              # Synthetic data
â”œâ”€â”€ notebooks/         # (Optional) Exploration notebooks
â”œâ”€â”€ src/               # Core logic modules
â”œâ”€â”€ results/           # Outputs and visualizations
â”œâ”€â”€ appendix/          # LaTeX appendix for submission
â”œâ”€â”€ scripts/           # Run experiments
â”œâ”€â”€ requirements.txt   # Dependencies
â””â”€â”€ README.md          # This file
```

---

## â–¶ï¸ Running the Experiment
```bash
python scripts/run_experiment.py
```

Outputs include:
- Total utility
- Exposure disparity
- Envy violations
- `results/exposure_matrix.csv`

---

## ğŸ“Š Sample Results
| Method           | Utility | Exposure Disparity | Envy Count |
|------------------|---------|---------------------|-------------|
| Top-k Relevance | 0.87    | High                | 42          |
| FEA ($\delta$=0.1) | 0.83    | 0                   | 0           |

---

## ğŸ“– Citation
```
@inproceedings{your2025fairness,
  title={Fairness in Human-Centered Knowledge Access},
  author={},
  booktitle={},
  year={2025}
}
```

## ğŸ“œ License
MIT License
